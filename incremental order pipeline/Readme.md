# Delta Live Tables: Incremental Orders Pipeline (E-Commerce)

## ğŸ“Œ Overview
A real-world simulation of an incremental order processing pipeline using **Delta Live Tables (DLT)** in Databricks.

## ğŸ§ª Scenario
- JSON order logs are ingested daily into `/mnt/raw/orders/`
- Pipeline processes data into:
  - **Bronze Table**: Raw ingestion
  - **Silver Table**: Deduplicated & clean (SCD Type 1 logic)
  - **Gold Table**: Daily revenue summary

## ğŸ§° Technologies
- Databricks
- PySpark
- Delta Live Tables (DLT)
- JSON logs, Delta Lake, Parquet

## ğŸ“‚ Project Structure
---
dlt-incremental-orders-pipeline/
â”œâ”€â”€ dlt_pipeline.py
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ orders_2025-07-01.json
â”‚ â”œâ”€â”€ orders_2025-07-02.json
â”‚ â””â”€â”€ orders_2025-07-03.json
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
---


## ğŸš€ How to Run
1. Upload `dlt_pipeline.py` to a Databricks Workspace
2. Create a new **Delta Live Table Pipeline**
   - Source: `/mnt/raw/orders/`
   - Target: `/mnt/dlt_output/`
3. Monitor Bronze â†’ Silver â†’ Gold outputs

## âœ… Output Tables
- `bronze_orders`
- `silver_orders`
- `gold_daily_sales`

## ğŸ‘¨â€ğŸ’» Author
Navin Shah | Data Engineer
